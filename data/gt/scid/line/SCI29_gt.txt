Abstract
small black and brown dog play with red ball in the grass
dog play with a red ball in
In this paper, we propose multimodal convolutional neu-
the grass
ral networks (m-CNNs) for matching image and sentence.
small black and brown dog
play with a red ball
Our m-CNN provides an end-to-end framework with convo-
lutional architectures to exploit image representation, word
black and
a red ball
composition, and the matching relations between the two
brown dog
modalities. More specifically, it consists of one image CNN
encoding the image content and one matching CNN mod-
grass
ball
dog
eling the joint representation of image and sentence. The
matching CNN composes different semantic fragments from
Figure 1. Multimodal matching relations between image and
words and learns the inter-modal relations between image
sentence. The words and phrases, such as "grass", "a red
and the composed fragments at different levels, thus ful-
ball", and "small black and brown dog play
ly exploit the matching relations between image and sen-
with a red ball", correspond to the image areas of their
grounding meanings. The sentence "small black and
tence. Experimental results demonstrate that the proposed
brown dog play with red ball in the grass"
m-CNNs can effectively capture the information necessary
expresses the meaning of the whole image.
for image and sentence matching. More specifically, our
proposed m-CNNs significantly outperform the state-of-
whole sentence "small black and brown dog play
the-art approaches for bidirectional image and sentence re-
with a red ball in the grass", expressing a com-
trieval on the Flickr8K and Flickr3OK datasets.
plete meaning, associates with the whole image. These
matching relations should be all taken into consideration for
an accurate multimodal matching between image and sen-
1. Introduction
tence. Recently, much research work focuses on modeling
Associating image with natural language sentence plays
the image and sentence matching relation at the specific lev-
