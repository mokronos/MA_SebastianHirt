\chapter{Quality Assessment}
\label{chap:qualityassessment}

In this section, we go over the metrics used in this thesis.

\section{Character Error Rate}
\label{subsec:cer}

The \gls{cer} describes how many substitutions, deletions, and insertions are necessary to transform a text prediction into the text label.
It is defined as follows.

\begin{equation}
    \text{CER} = \frac{S + D + I}{N},
    \label{eq:cer}
\end{equation}
with \(S\) being the number of substitutions, \(D\) the number of deletions, \(I\) the number of insertions, and \(N\) the total number of characters of the label.
The \gls{cer} ranges from 0 to $\infty$, where 0 means perfect recognition and the higher the worse the recognition.
Because the \gls{mos} is defined in the range 0 to 100 and 100 represents a high subjective quality, the two metrics are unintuitive to compare.
Therefore, we are transforming the CER by subtracting it from 1 and multiplying it by 100 to get a \gls{mos}-like value, see \autoref{eq:cer2mos}.

\begin{equation}
    \text{CER}_{comp} = (1 - \text{CER}) \cdot 100
    \label{eq:cer2mos}
\end{equation}

This means that the $\text{CER}_{comp}$ can be in the range -$\infty$ to 100, where 100 means perfect recognition and the lower the worse the recognition.
Although the $\text{CER}_{comp}$ is generally in the range 0 to 100, which matches the \gls{mos}.

\section{Peak Signal-to-Noise Ratio}
\label{subsec:psnr}

The \gls{psnr} \cite{PSNRvsSSIM_2010} describes the ratio of the maximum possible power of a signal and the power of corrupting noise that affects it.
When it is applied to an image, the \gls{psnr} is defined as follows.

\begin{equation}
    \text{PSNR} = 10 \cdot \log_{10} \left( \frac{R^2}{\text{MSE}} \right),
    \label{eq:psnr}
\end{equation}

with \(R\) being the maximum possible pixel value of the image and MSE being the \gls{mse} between the original and the reconstructed image.

\section{Bj√∏ntegaard Delta Rate}
\label{subsec:bdrate}

The \gls{bdrate} \cite{bdrate_original_2001}\cite{bdrate_beyond_2022} (can't find pdf of original paper) is defined by the difference between the integration of curves of the codecs to compare.
The first curve is the reference curve and the second the test curve.
Both are plotting some average metric over the average bitrate of some images.

\begin{equation}
    \text{BDRate} = https://arxiv.org/pdf/2202.12565.pdf
    \label{eq:bdrate}
\end{equation}

\section{Correlation}
\label{sec:correlation}

In this section, we describe the correlation methods we use to compare the behavior of the \gls{mos} and the \gls{cer}.
These can then be used to determine if the \gls{cer} is a good alternative for the \gls{mos}.
We are using the sample form of the correlations, because we want to make a statement about a much larger population of images, not just our dataset.

\subsection{Pearson Correlation}
\label{subsec:pearson}

The \gls{plcc} \cite{pears_spear_2016} describes the linear correlation between two variables, normalized to the range $[-1, 1]$.
Given the $i$th image in our dataset, its subjective and objective scores are $s_i$ and $o_i$ respectively.
The \gls{plcc} is then defined as follows.

\begin{equation}
    r_p = \frac{\sum_{i=1}^{N}{(o_i-\overline{o})(s_i-\overline{s})}}{\sqrt{\sum{(o_i-\overline{o})^2}\sum{(s_i-\overline{s})^2}}},
    \label{eq:pearson}
\end{equation}

with $\overline{o}$ and $\overline{s}$ representing the mean values of $o_i$ and $s_i$ respectively.
$N$ is the total number of images in the images used in the experiment.
If the \gls{plcc} is close to 1, the two vectors have a positive linear relationship, which means that if $o_i$ increases, $s_i$ increases as well.
If the \gls{plcc} is close to -1, the two vectors have a negative linear relationship, which means that if $o_i$ increases, $s_i$ decreases.
If the \gls{plcc} is close to 0, the two vectors have no correlation at all.

\subsection{Spearman Ranked Correlation}
\label{subsec:spearman}

The \gls{srcc} \cite{pears_spear_2016} describes the monotonic correlation between two variables, normalized to the range $[-1, 1]$.
Compared to the \gls{plcc}, it mainly takes the order/rank of the values into account, not the exact values.
The scores $o_i$ and $s_i$ are transformed into their ranks $o_{i,r}$ and $s_{i,r}$ respectively with values in the range $[1, N]$.
If for example, the two first values are tied their rank is set to the mean, in this case $(1+2)/2 = 1.5$.
With these values, the \gls{srcc} is defined as follows.

\begin{equation}
    r_s = \frac{\sum_{i=1}^{N}{(o_{i,r}-\overline{o_r})(s_{i,r}-\overline{s_r})}}{\sqrt{\sum{(o_{i,r}-\overline{o_r})^2}\sum{(s_{i,r}-\overline{s_r})^2}}},
    \label{eq:spearman}
\end{equation}

with $\overline{o_r}$ and $\overline{s_r}$ representing the mean values of the $o_{i,r}$ and $s_{i,r}$ vectors respectively.
If the \gls{srcc} is close to 1, the two vectors have a positive monotonic relationship, which means that the rank of $o_i$ increases, the rank of $s_i$ increases as well.
If the \gls{srcc} is close to -1, the two vectors have a negative monotonic relationship, which means that the rank of $o_i$ increases, the rank of $s_i$ decreases.
If the \gls{srcc} is close to 0, the ranks of the two vectors have no correlation at all.
These characteristics will help us to determine if the \gls{cer} is a good alternative for the \gls{mos}, by checking how similar the ranks of the two metrics are.

\section{Nonlinear Transformation}
\label{sec:nonlinear}

In this section, we describe the nonlinear curve fitting used to transform the \gls{mos} to remove nonlinearities.
This is mainly done because the subjective scores have been found to have nonlinear quality rating compression at the extremes of the test range \cite{nonlin_fit_original_2000}.
The model used for the fitting was defined in \cite{nonlin_fit_original_2000}, although we leave out the extension suggested in the paper.
It can be defined as follows.

\begin{equation}
    s_{i,p} = a * (\frac{1}{2} - \frac{1}{1 + \exp{b * (x - c)}}) + d * x + e
    \label{eq:nonlinear}
\end{equation}

\begin{equation}
    \textrm{MOS}_{i,p} = \frac{\beta_{1}-\beta_{2}}{1 + e^{-\left(\frac{\textrm{CER}_{c,i}-\beta_{3}}{|\beta_{4}|}\right)}} + \beta_{4}
\end{equation}

with $\text{MOS}_{p}$ representing the predicted \gls{mos} value, $\text{MOS}$ the original \gls{mos} value, and $a$, $b$, $c$, and $d$ the parameters of the model.

- random, empirical selection can lead to local optimal solutions
The parameters are initialized as follows.
 
\begin{equation}
    \begin{aligned}
        a &= \max{CER} \\
        b &= \min{CER} \\
        c &= \overline{MOS} \\
        d &= 1
    \end{aligned}
    \label{eq:nonlinear_init}
\end{equation}
The parameters are adjusted with the least squared method until the model fits the data of all the images.
We then use the model and the \gls{cer} values the predict the transformed $\text{MOS}_{p}$ values.
A similar fitting was used in \cite{nonlin_fit_2011}\cite{nonlin_fit_appl_2017}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{../exp/fit_example.pdf}
    \caption{Example of the nonlinear fit with subjective and objective values}
    \label{fig:nonlinear_fit}
\end{figure}

In Figure \ref{fig:nonlinear_fit}, we can see an example of the nonlinear fit.
First we have some random data from subjective and objective values, which might represent the \gls{mos} and \gls{cer} values of some images.
We then use the model and the parameters and fit the model to the data.
The fitted curve clearly fits the data better than the curve with the initial parameters.
Additionally we can calculate the \gls{plcc} and \gls{srcc} of the two curves.
We see that the \gls{plcc} and \gls{srcc} of the fitted curve are higher than the \gls{plcc} and \gls{srcc} of the curve with the initial parameters.
With the \gls{plcc} it is not as obvious to see, but for the \gls{srcc} we can clearly see that the fitted curve is monotonic, while some of the initial datapoints are ranked first on the subjective value, but a higher rank on the objective value.
This leads to a \gls{srcc} of 1 for the fitted data, but a slightly lower \gls{srcc} for the initial data.

We can use this method later to transform the \gls{mos} to improve the correlation with the \gls{cer}.

\section{Root Mean Squared Error}
\label{sec:rmse}

The \gls{rmse} is a metric that measures the average magnitude of the error between the predicted values and the actual values.
It is defined as follows.

\begin{equation}
    \textrm{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}{(o_i - s_i)^2}},
    \label{eq:rmse}
\end{equation}

with $o_i$ and $s_i$ representing the predicted and actual values respectively.
