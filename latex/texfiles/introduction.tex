\chapter{Introduction}
\label{chap:Introduction}


In todayâ€™s digital age, screen content plays a vital role in our daily lives.
From office work to entertainment, we are constantly interacting with images and videos on screens.
Many of these images contain text, graphics and user interface elements that are not found in natural images.
As such, the quality of screen content is of utmost importance for the viewer.
One key aspect of screen content quality is the readability of text.
However, conventional objective \gls{iqa} algorithms do not directly consider text readability.
This is where \gls{ocr} algorithms come into play.

In this thesis, we will explore the application of \gls{ocr} algorithms for the assessment of screen content image quality.
We research state-of-the-art \gls{ocr} methods, generate a labeled dataset and investigate the correlation between the performance of \gls{ocr} and human judgment on images with different types of distortion.
Additionally, we investigate the feasibility of using the quality of \gls{ocr} algorithms to compare codecs.
Through a structured implementation and detailed documentation of the framework and experiments, we provide valuable insights into the potential of \gls{ocr} algorithms for screen content \gls{iqa}.
In this thesis, I use the pronouns \textit{we} and \textit{our} to refer to myself and the larger scientific community.

This thesis is structured as follows.
First, we describe which conventional \gls{iqa} methods exist for natural images and which methods are used to assess screen content images in \autoref{chap:qualityassessment}.
Further, we detail the evaluation procedure we apply to compare the performance of \gls{iqa} methods.
In \autoref{chap:ocr}, we initially describe conventional \gls{ocr} methods and then focus on the state-of-the-art \gls{ocr} methods.
Additionally, we introduce the two \gls{ocr} methods, Tesseract \gls{ocr} \cite{tesseract_legacy_2007} and EasyOCR \cite{easyocr_gitub_2020}, which we use in our experiments.
In \autoref{chap:dataset}, we detail the different types of distortion in the SCID dataset \cite{ni_esim_2017} used in this thesis and describe the labeling procedure we employ to generate text labels for the dataset.
Further, the extension of the dataset by incorporating images distorted with \gls{hevc} \cite{hevc_2012} and \gls{vvc} \cite{vvc_2021} is explained.
In \autoref{chap:evaluation} we compare the performance of Tesseract \gls{ocr} and EasyOCR for the different types of distortion, and investigate the correlation between the performance of \gls{ocr} and human judgment.
Afterwards, we investigate the feasibility of using the predictions of the \gls{ocr} algorithms to compare codecs.
Finally, we summarize and conclude our findings in \autoref{chap:conclusion}.
