\chapter{Abstract}

In today's digitally interconnected world, screen content images play a significant role in various applications such as video conferencing, remote desktop access, and video streaming, making image quality a crucial aspect for enhancing user experience.
However, conventional image quality assessment methods like peak signal-to-noise ratio and structural similarity index are inadequate for screen content images containing text.
This thesis explores the application of \gls{ocr} algorithms for evaluating screen content image quality.
Initially, we research state-of-the-art \gls{ocr} methods, comparing the performance of Tesseract \gls{ocr} and EasyOCR using the SCID dataset. 
As the dataset lacks text labels, we annotate the dataset to evaluate the effectiveness of the \gls{ocr} methods.
Additionally, we investigate the correlation between the performance of \gls{ocr} and human judgment on images with different types of distortion by comparing the character error rate with the subjective mean opinion score included in the dataset.
Furthermore, we expand the SCID dataset by incorporating images distorted with high-efficiency video coding and versatile video coding.
This extension enables us to explore whether \gls{ocr} can serve as a reliable ground truth for comparing different codecs, using the Bj√∏ntegaard Delta Rates between different rate-distortion curves.
Our findings suggest that \gls{ocr} holds promise as a valuable tool for screen content image quality assessment for certain types of distortion, particularly when complemented with other metrics, that evaluate the quality of the graphical parts of images.
Additionally, our results indicate that EasyOCR proves to be a suitable source for generating the pseudo ground truth for codec comparison.
