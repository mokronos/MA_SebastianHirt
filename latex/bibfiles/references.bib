/* ################################################################ */
/* Dataset */
/* ################################################################ */

@article{ni_esim_2017,
	title = {{ESIM}: {Edge} {Similarity} for {Screen} {Content} {Image} {Quality} {Assessment}},
	volume = {26},
	issn = {1057-7149, 1941-0042},
	shorttitle = {{ESIM}},
	url = {http://ieeexplore.ieee.org/document/7954714/},
	doi = {10.1109/TIP.2017.2718185},
	abstract = {In this paper, an accurate full-reference image quality assessment (IQA) model developed for assessing screen content images (SCIs), called the edge similarity (ESIM), is proposed. It is inspired by the fact that the human visual system (HVS) is highly sensitive to edges that are often encountered in SCIs; therefore, essential edge features are extracted and exploited for conducting IQA for the SCIs. The key novelty of the proposed ESIM lies in the extraction and use of three salient edge features—i.e., edge contrast, edge width, and edge direction. The ﬁrst two attributes are simultaneously generated from the input SCI based on a parametric edge model, while the last one is derived directly from the input SCI. The extraction of these three features will be performed for the reference SCI and the distorted SCI, individually. The degree of similarity measured for each above-mentioned edge attribute is then computed independently, followed by combining them together using our proposed edge-width pooling strategy to generate the ﬁnal ESIM score. To conduct the performance evaluation of our proposed ESIM model, a new and the largest SCI database (denoted as SCID) is established in our work and made to the public for download. Our database contains 1800 distorted SCIs that are generated from 40 reference SCIs. For each SCI, nine distortion types are investigated, and ﬁve degradation levels are produced for each distortion type. Extensive simulation results have clearly shown that the proposed ESIM model is more consistent with the perception of the HVS on the evaluation of distorted SCIs than the multiple state-of-the-art IQA methods.},
	language = {en},
	number = {10},
	urldate = {2023-03-09},
	journal = {IEEE Transactions on Image Processing},
	author = {Ni, Zhangkai and Ma, Lin and Zeng, Huanqiang and Chen, Jing and Cai, Canhui and Ma, Kai-Kuang},
	month = oct,
	year = {2017},
	pages = {4818--4831},
}

/* ################################################################ */
/* OCR */
/* ################################################################ */

@INPROCEEDINGS{tesseract_2007,
  author={Smith, R.},
  booktitle={Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)}, 
  title={An Overview of the Tesseract OCR Engine}, 
  year={2007},
  volume={2},
  number={},
  pages={629-633},
  doi={10.1109/ICDAR.2007.4376991}
}

@misc{easyocr_2020,
    title = {Easyocr},
    author = {Jaided},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/JaidedAI/EasyOCR}}
}


