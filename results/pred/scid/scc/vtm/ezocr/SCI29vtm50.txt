Abstract small black and brown dog plav with red ball in the grass play with red balin In this paper; we propose multimodal convolutional neu- uass ral networks (m-CNNs) for matching image and sentence: amallblackang brdwh dDB red ball Our m-CNN provides un end-to-end framework with convo- lutional architectures to exploit image representation, word black and red wal composition, and the matching relations between the two brwn dpg modalities: More specifically; it consists of one image CNN encoding the image content and one matching CNN mod- the joint representation of image and sentence: The matching CNN composes different semantic fragments from Figure Multimodal  matching   relations   between   image   and words and learns the inter-modal relations between image sentence. The  words and phrases, such as grass red and the composed fragments at different levels, thus ful- ball"_ and small black and brown dog play ly exploit the matching relations between image and sen- with red ball". correspond t0 the image areas of their tence Experimental results demonstrate that the proposed grounding   meanings The sentence small black and m-CNNs can effectively capture the information necessary brown dog play with red ball in the grass for image and sentence matching: More specifically Oltr expresses the meaning of the whole image: proposed m-CNNs  significamly outpetform the state-of the-art approaches for bidirectional image and sentence re - whole sentence 'small black and brown dog play trieval on the FlickrSK and Flickr3OK datasets: with red ball in the grass expressing a com- plete meaning; associates with the whole image. These matching relations should be all taken into consideration for 1. Introduction an accurate multimodal matching between image and sen- tence. Recently. much research work focuses 0n modeling Associating image with natural language sentence plays the image and sentence matching relation at the specific lev- dog [ eling