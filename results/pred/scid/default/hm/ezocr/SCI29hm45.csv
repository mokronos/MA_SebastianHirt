left,top,right,bottom,text,conf
266,12,377,40,Abstract,1.0
865,23,1079,39,small black and brown dog play with,0.73
1087,21,1205,39,red ball in the grass,0.81
1017,73,1115,87,plav with a red ballin,0.72
64,73,608,102,In this paper; we propose multimodal convolutional neu-,0.78
1035,87,1079,99,Lheerass,0.65
33,98,607,134,ral networks (m-CNNs) for matching image and sentence:,0.65
995,117,1065,131,small olack anc,0.8
1067,117,1117,129,browin DOg,0.16
1013,131,1103,145,play with a red ball,0.9
36,129,600,158,Our m-CNN provides an end-to-end framework with convo-,0.67
34,160,270,184,lutional architectures I0,0.67
336,159,608,189,"image representation, word",0.66
1123,179,1171,191,black and,0.74
983,187,1023,199,red ball,0.81
33,185,608,218,"composition, and the matching relations between the two",0.76
1121,193,1173,205,brown dog,0.66
34,216,608,246,modalities: More specifically; it consists of one image CNN,0.89
32,239,607,277,encoding the image content and one matching CNN mod-,0.71
90,275,556,304,the joint representation of image and sentence.,0.53
564,273,609,300,The,1.0
32,297,609,334,matching CNN composes different semantic fragments from,0.71
656,310,718,338,Figure,0.7
751,304,1229,340,Multimodal   matching   relations   between image and,0.57
36,332,608,360,words and learns the inter-modal relations between image,0.7
654,340,740,358,sentence.,0.96
752,338,1048,364,"The words and phrases, such as",0.65
1058,340,1130,364,'grass,0.56
1185,339,1227,359,red,1.0
34,359,608,391,"and the composed fragments at different levels,   thus ful-",0.55
656,364,724,388,"ball""_",0.53
763,367,799,385,and,1.0
835,362,904,389,small,1.0
912,363,1112,388,black and brown,0.81
1118,364,1228,390,dog play,0.32
34,385,560,418,ly exploit the matching relations between image and,0.58
565,397,607,413,sen-,0.98
657,391,711,411,with,0.7
746,389,1230,417,"red ball"". correspond t0 the image areas of their",0.72
35,421,93,441,tence.,0.54
102,417,609,448,Experimental results demonstrate that the proposed,0.9
656,412,850,443,grounding   meanings,0.72
883,417,921,437,The,1.0
931,419,1009,437,sentence,1.0
1029,414,1098,441,small,1.0
1104,416,1178,440,black,1.0
1184,416,1228,440,and,1.0
39,455,67,471,m-,0.46
66,446,608,474,CNNs can effectively capture the information necessary,0.65
657,445,725,465,brown,1.0
783,442,842,470,play,1.0
849,445,905,465,with,0.97
941,445,983,465,red,1.0
991,445,1047,465,ball,0.56
1057,445,1087,465,in,1.0
1095,445,1137,465,che,0.57
1146,446,1216,470,grass,1.0
31,470,376,506,for image and sentence matching:,0.66
388,474,564,502,More specifically;,0.92
571,483,609,499,our,0.98
653,463,1034,499,expresses the meaning of the whole image:,0.85
33,505,130,533,proposed,0.69
134,501,606,533,m-CNNs significantly outperform the state-of:,0.65
34,531,608,563,the-art approaches for bidirectional image and sentence re -,0.8
656,522,720,546,whole,1.0
727,522,816,548,sentence,1.0
836,522,982,549,small black,0.99
992,522,1228,551,and brown dog play,0.94
34,560,494,586,trieval on the FlickrSK and Flickr3OK datasets:,0.51
657,555,713,575,with,1.0
747,555,789,575,red,1.0
797,555,853,575,ball,1.0
863,555,893,575,in,1.0
900,552,1022,580,the grass,1.0
1041,547,1152,580,expressing,1.0
1155,555,1227,575,a com-,0.76
655,575,1152,611,plete  meaning; associates with the whole image:,0.51
1166,580,1228,604,These,1.0
653,601,1231,639,matching relations should be all taken into consideration for,0.86
36,646,226,676,1. Introduction,0.98
656,636,890,662,an accurate multimodal,0.84
888,631,1229,668,matching between image and sen-,0.8
654,665,1130,694,"tence. Recently, much research work focuses 0n",0.51
1129,659,1230,697,modeling,1.0
62,691,609,720,Associating image with natural language sentence plays,0.73
654,694,690,718,the,1.0
752,690,1228,720,and sentence matching relation at the specific lev-,0.86
997,71,1020,88,dog [,0.1
268,164,342,183,exploit,0.99
36,270,91,306,eling,1.0
734,439,781,472,dog,1.0
689,690,756,725,image,0.99
