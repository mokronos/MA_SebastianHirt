Abstract small black and brown dog play with red ball in the grass plav with a red ballin In this paper; we propose multimodal convolutional neu- Lheerass ral networks (m-CNNs) for matching image and sentence: small olack anc browin DOg play with a red ball Our m-CNN provides an end-to-end framework with convo- lutional architectures I0 image representation, word black and red ball composition, and the matching relations between the two brown dog modalities: More specifically; it consists of one image CNN encoding the image content and one matching CNN mod- the joint representation of image and sentence. The matching CNN composes different semantic fragments from Figure Multimodal   matching   relations   between image and words and learns the inter-modal relations between image sentence. The words and phrases, such as 'grass red and the composed fragments at different levels,   thus ful- ball"_ and small black and brown dog play ly exploit the matching relations between image and sen- with red ball". correspond t0 the image areas of their tence. Experimental results demonstrate that the proposed grounding   meanings The sentence small black and m- CNNs can effectively capture the information necessary brown play with red ball in che grass for image and sentence matching: More specifically; our expresses the meaning of the whole image: proposed m-CNNs significantly outperform the state-of: the-art approaches for bidirectional image and sentence re - whole sentence small black and brown dog play trieval on the FlickrSK and Flickr3OK datasets: with red ball in the grass expressing a com- plete  meaning; associates with the whole image: These matching relations should be all taken into consideration for 1. Introduction an accurate multimodal matching between image and sen- tence. Recently, much research work focuses 0n modeling Associating image with natural language sentence plays the and sentence matching relation at the specific lev- dog [ exploit eling dog image