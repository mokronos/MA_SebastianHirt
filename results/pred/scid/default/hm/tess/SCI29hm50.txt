Abstract ‘emall black viet henwn flog play with s.r fal i tte pros U In thas paper, we propose multimadal convolutional neu- (a ral networks (m-CNNs) for matching image and sentence. Our m-CNN provides an end-to-end framework with convo- lutional architectures to exploit Image representation, word composition, and the matching relations between the two medalines. More specifically, it consists of one image CNN’ encading the image content arul ane matching CNN mod- eling the joint representation of image and sentence. The matching CNN composes different semantic fragments Jrom Figure | Multimodal watching relutious between imaye und words and learns the inter-modal relations between image sentence. The words and phrases, such “grass”, “a red us and the composed fragments at different levels, thus ful- ball”, and “sita11 black and brown dog play ly explait the matching relations between image und sen- with a red ball", correspond to the mage areas of their tence. Experimental results demonstrate that the proposed grounding meumogs, The semence “smslil black and m-CNNs effectively capture the information brown dog play with a red ball in the grass” can necessary for image and matching. More specifically, expresses the meaning of the whole image. sentence our proposed in-CNNs significantly outperform the state-of and whole setitence “stall black and brown dog play the-art approaches for bidirectional image sentence re- trieval the Flickr8K and Flickr30K datasets. With @ red p2l! in the grass”, expressing a com- un plete meaning, associates with the whole image. These matching relations should be all taken into consideration for 1, Intreduction an accurae multimodal marching between image and sen- tence. Recently, much research work focuses on modeling Associating image with natural language sentence plays the imuye wad sentence matchuny relutiun at the specific lev-